{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################ \n",
    "# Bootcamp Project 2\n",
    "# Gary Schulke\n",
    "# January 16, 2020\n",
    "############################################################################################\n",
    "############################################################################################\n",
    "############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################ \n",
    "# Section 1\n",
    "# This section is for the census data.\n",
    "# The files have been converted from PDF to xlsx and partially cleaned with VB \n",
    "# and saved as csv.\n",
    "############################################################################################ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish cleaning with Pandas\n",
    "# Comment / uncomment out file and periodTags as need.\n",
    "# The path to our CSV file\n",
    "\n",
    "source_folder = 'Resources/'\n",
    "json_folder = 'JSON/'\n",
    "clean_csv_folder = 'CleanCSV/'\n",
    "\n",
    "file = \"stop_level_passenger_census_sorted_by_location_id_weekdaySpring2018.xlsx.csv\"\n",
    "periodTag = 'Spring2018'\n",
    "\n",
    "file = \"stop_level_passenger_census_sorted_by_bus_stop_name_weekdayFall2018.xlsx.csv\"\n",
    "periodTag = 'Fall2018'  # Will be sorted by locaton id at the end of script to match others.\n",
    "\n",
    "file = \"stop_level_passenger_census_sorted_by_location_id_weekdaySpring2019.xlsx.csv\"\n",
    "periodTag = 'Spring2019'\n",
    "\n",
    "file = \"stop_level_passenger_census_sorted_by_location_id_weekdayFall2019.xlsx.csv\"\n",
    "periodTag = 'Fall2019'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data into pandas\n",
    "df = pd.read_csv(source_folder + file)\n",
    "# Show and area that will need to be cleaned.\n",
    "df.iloc[46:56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get a list of all of our columns, columns named deleteX will be deleted for easy reference.\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data we want to keep has all its columns filled.  dropna() will get rid of all the\n",
    "# headers and titles in the middle of the document.\n",
    "# If this line errors due to no column name 'Unnamed: 8', continue with next cell.\n",
    "df.drop(['Unnamed: 8'], axis = 1, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df.iloc[46:56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There may be a few headers left.\n",
    "indexNames = df[ df['location_id'] == 'Location ID' ].index\n",
    "print(indexNames)\n",
    "# Delete these row indexes from dataFrame\n",
    "df.drop(indexNames , inplace=True)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In there is no error, all the data is there.\n",
    "df['location_id'] = df[\"location_id\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The large numbers have commas in them, remove the comma and convert to int.\n",
    "# If there is any data missing, the conversion to int will fail.\n",
    "df['total'] = df['total'].str.replace(',' , '').astype(int)\n",
    "df['offs'] = df['offs'].str.replace(',' , '').astype(int)\n",
    "df['ons'] = df['ons'].str.replace(',' , '').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the sample period.\n",
    "df['period'] = periodTag\n",
    "df.sort_values(by=['location_id'], inplace=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup and setup output path.\n",
    "new_path = file.split('.' , 1)\n",
    "new_path = new_path[0] + '.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(source_folder + json_folder + new_path, orient=\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.to_csv(source_folder + clean_csv_folder + \n",
    "          'stop_level_passenger_census_sorted_by_location_id_weekday' + \n",
    "           periodTag + '_Cleaned.csv',index=True)\n",
    "periodTag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "############################################################################################\n",
    "############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################ \n",
    "# Section 2\n",
    "# This section if for the routes data.\n",
    "# The files have been converted from PDF to xlsx and partially cleaned with VB \n",
    "# and saved as csv.\n",
    "############################################################################################ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish cleaning with Pandas\n",
    "# Comment out file and periodTag as neeed to run each file.\n",
    "# The path to our CSV file\n",
    "source_folder = 'Resources/'\n",
    "json_folder = 'JSON/'\n",
    "clean_csv_folder = 'CleanCSV/'\n",
    "\n",
    "file = \"route_ridership_report_sorted_by_route_weekdaySpring2018.xlsx.csv\"\n",
    "periodTag = 'Spring2018'\n",
    "\n",
    "file = \"route_ridership_report_sorted_by_route_weekdayFall2018.xlsx.csv\"\n",
    "periodTag = 'Fall2018' \n",
    "\n",
    "\n",
    "file = \"route_ridership_report_sorted_by_route_weekdaySpring2019.xlsx.csv\"\n",
    "periodTag = 'Spring2019'\n",
    "\n",
    "file = \"route_ridership_report_sorted_by_route_weekdayFall2019.xlsx.csv\"\n",
    "periodTag = 'Fall2019'  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data into pandas\n",
    "df = pd.read_csv(source_folder + file)\n",
    "df.iloc[50:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get a list of all of our columns \n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the unwanted columns.  The original xlsx file had columns that aren't wanted \n",
    "# and stray data in some of the outside columns.  They were headed in the VB scripts to \n",
    "# make them obvious.\n",
    "df.drop([\"delete1\", \"delete2\", \"delete3\", \"delete4\", \"delete5\"], axis = 1, inplace = True) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "df = df.dropna()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Route number from name\n",
    "route_number = df['full_route'].str.split(\"-\", n = 1, expand = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_number.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These source files had the route number and the location name merged into one cell. \n",
    "# This separates them.\n",
    "df[\"route_number\"]= route_number[0]\n",
    "df['route_name'] =   route_number[1]\n",
    "\n",
    "df.iloc[4:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna()  # Get rid of the rows with 'None' in them.\n",
    "# Don't need the combo number+name column.\n",
    "df = df.drop(['full_route'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange the columns\n",
    "df = df[['route_number', 'route_name', 'boarding_rides', 'rides_rev_hour', 'rides_veh_hour',\n",
    "         'cost_per_ride', 'passenger_miles', 'ave_trip_length']]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the entire column is filled.\n",
    "df['route_number'] = df[\"route_number\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the period to identify the time period of the data.\n",
    "df['period'] = periodTag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by route number to make it similar to the census data.\n",
    "df.sort_values(by=['route_number'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove those pesky dollar signs.\n",
    "remove_dollar = df['cost_per_ride'].str.split(\"$\", n = 1, expand = True)\n",
    "\n",
    "df['cost_per_ride'] = remove_dollar[1]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the comma from long numbers.\n",
    "df['passenger_miles'] = df['passenger_miles'].str.replace(',' , '').astype(int)\n",
    "df.iloc[7:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup and setup output path.\n",
    "new_path = file.split('.' , 1)\n",
    "new_path = new_path[0] + '.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to jason\n",
    "df.to_json(source_folder + json_folder + new_path, orient=\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rite to CSV\n",
    "df.to_csv(new_path + '_Clean.csv',index=True)\n",
    "periodTag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "############################################################################################\n",
    "############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################ \n",
    "# Section 3\n",
    "# This section adds data from the census json files to the file tm_stops.json\n",
    "# \n",
    "#\n",
    "############################################################################################ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = 'Resources/'\n",
    "json_folder = 'JSON/'\n",
    "clean_csv_folder = 'CleanCSV/'\n",
    "source_file = \"tm_stops.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the original tm_stops.json file.\n",
    "with open(source_folder + source_file) as json_file:\n",
    "    tm_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tm_dict['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "# Come back to this step for each data file to be added to the source file.\n",
    "###########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment each line to process each file.\n",
    "file = 'stop_level_passenger_census_sorted_by_location_id_weekdaySpring2019.json'\n",
    "file = 'stop_level_passenger_census_sorted_by_location_id_weekdaySpring2018.json'\n",
    "file = 'stop_level_passenger_census_sorted_by_location_id_weekdayFall2019.json'\n",
    "file = 'stop_level_passenger_census_sorted_by_bus_stop_name_weekdayFall2018.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(source_folder + json_folder + file) as json_file:\n",
    "    census_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(census_dict['data'][0]['location_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(census_dict['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleperiod = census_dict['data'][0]['period'].lower()\n",
    "sampleperiod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put a default value for sample period in every feature.properties. \n",
    "# There won't be data for all of them.  This makes the logic simpler.\n",
    "tm_size = len(tm_dict['features'])\n",
    "for i in range(tm_size):\n",
    "     tm_dict['features'][i]['properties'][sampleperiod] = 'No Data'\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_dict['features'][0]['properties'][sampleperiod]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_size = len(tm_dict['features'])\n",
    "cn_size = len(census_dict['data'])\n",
    "matched = False\n",
    "m_count = 0\n",
    "matched = True\n",
    "not_matched = 0\n",
    "for i in range(tm_size):\n",
    "    if not matched:\n",
    "        not_matched += 1\n",
    "        print (\"stop_id \" , str(tm_dict['features'][i-1]['properties']['stop_id']), ' did not match!')\n",
    "    matched = False\n",
    "    for j in range(cn_size):\n",
    "        stop_id = int(tm_dict['features'][i]['properties']['stop_id'])\n",
    "        location_id = int(census_dict['data'][j]['location_id'])\n",
    "        period = census_dict['data'][j]['period'].lower()\n",
    "        total = census_dict['data'][j]['total']    \n",
    "        if (stop_id == location_id):\n",
    "            matched = True\n",
    "            m_count += 1\n",
    "            tm_dict['features'][i]['properties'][period] = str(total)\n",
    "print('Complete')\n",
    "print(str(not_matched) , ' Did not match.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check one\n",
    "tm_dict['features'][0]['properties'][sampleperiod]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# go back and uncomment the next data file\n",
    "# don't write it out until all data files are complete.\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = 'Resources/'\n",
    "json_folder = 'JSON/'\n",
    "clean_csv_folder = 'CleanCSV/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(source_folder + json_folder + 'm_' + source_file, 'w') as outfile:\n",
    "    json.dump(tm_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
